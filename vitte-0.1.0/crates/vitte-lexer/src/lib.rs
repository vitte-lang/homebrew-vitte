//! vitte-lexer â€” analyse lexicale pour Vitte (version ++)
//!
//! Faits saillants :
//! - `Lexer` + `LexerOptions` : commentaires `//`, `/* */` (imbriquÃ©s), ident/keywords, nombres
//!   (2/8/10/16, `_`, floats + exposant), **chaÃ®nes** avec Ã©chappements, **raw strings** Ã  la Rust
//!   (`r".."`, `r#".."#`, â€¦), **char literal** `'a'`, `'\n'`, etc.
//! - `Span`/`Spanned`/`SourceId` + **LineMap** pour `(ligne, colonne)`
//! - Erreurs avec `Display` propre + spans prÃ©cis
//!
//! Exemple Ã©clair :
//! ```
//! use vitte_core::SourceId;
//! use vitte_lexer::{Lexer, LexerOptions, TokenKind};
//!
//! let src = r#"let s = r#"multi " raw"#; let c = '\n';"#;
//! let opts = LexerOptions::default();
//! let mut lx = Lexer::with_options(src, SourceId(0), opts);
//! while let Some(tok) = lx.next().transpose().unwrap() {
//!     if matches!(tok.value, TokenKind::Eof) { break; }
//!     // println!("{:?} @ {:?}", tok.value, tok.span);
//! }
//! ```

#![deny(missing_docs)]
#![cfg_attr(not(feature = "std"), no_std)]

use core::fmt;

#[cfg(feature = "std")]
use std::{string::String, vec::Vec};

#[cfg(not(feature = "std"))]
use alloc::{string::String, vec::Vec};
#[cfg(not(feature = "std"))]
extern crate alloc;

use vitte_core::{Pos, SourceId, Span, Spanned};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Options & LineMap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

/// Options du lexer.
#[derive(Debug, Clone, Copy)]
pub struct LexerOptions {
    /// Autoriser commentaires blocs imbriquÃ©s `/* ... /* .. */ ... */`.
    pub nested_block_comments: bool,
    /// Autoriser raw strings `r".."`, `r#".."#`, â€¦
    pub raw_strings: bool,
    /// Nombre max de `#` autorisÃ©s autour dâ€™un raw string (anti-DoS).
    pub max_raw_hashes: u8,
}

impl Default for LexerOptions {
    fn default() -> Self {
        Self {
            nested_block_comments: true,
            raw_strings: true,
            max_raw_hashes: 16,
        }
    }
}

/// Table des lignes pour (byte offset) â†’ (ligne, colonne).
#[derive(Debug, Clone)]
pub struct LineMap {
    /// Offsets des dÃ©buts de lignes (toujours contient 0).
    pub line_starts: Vec<u32>,
}

impl LineMap {
    /// Construit la table Ã  partir dâ€™un `&str`.
    pub fn new(src: &str) -> Self {
        let mut ls = Vec::with_capacity(64);
        ls.push(0);
        for (i, b) in src.as_bytes().iter().enumerate() {
            if *b == b'\n' {
                ls.push((i as u32) + 1);
            }
        }
        Self { line_starts: ls }
    }

    /// Convertit un `Pos` en (ligne, colonne), 1-based.
    pub fn line_col(&self, pos: Pos) -> (u32, u32) {
        let off = pos.0;
        // binary search
        let idx = match self.line_starts.binary_search(&off) {
            Ok(i) => i,
            Err(i) => i.saturating_sub(1),
        };
        let line_start = self.line_starts[idx];
        let col = off.saturating_sub(line_start) + 1;
        ((idx as u32) + 1, col)
    }

    /// Convertit un `Span` en ((l1,c1), (l2,c2)).
    pub fn span_lines(&self, sp: Span) -> ((u32, u32), (u32, u32)) {
        (self.line_col(sp.start), self.line_col(sp.end))
    }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

/// Mots-clÃ©s reconnus.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Keyword {
    /// `fn`
    Fn,
    /// `let`
    Let,
    /// `const`
    Const,
    /// `if`
    If,
    /// `else`
    Else,
    /// `while`
    While,
    /// `for`
    For,
    /// `return`
    Return,
    /// `struct`
    Struct,
    /// `enum`
    Enum,
    /// `true`
    True,
    /// `false`
    False,
    /// `null`
    Null,
}

/// Genre de jeton lexical.
#[derive(Debug, Clone, PartialEq)]
pub enum TokenKind<'a> {
    /// Fin de fichier.
    Eof,
    /// Identifiant (ou mot-clÃ© reclassÃ© dans `Keyword`).
    Ident(&'a str),
    /// Mot-clÃ©.
    Kw(Keyword),
    /// LittÃ©ral entier (i64).
    Int(i64),
    /// LittÃ©ral flottant (f64).
    Float(f64),
    /// LittÃ©ral char (un seul scalaire Unicode).
    Char(char),
    /// LittÃ©ral chaÃ®ne (dÃ©codÃ©e).
    Str(String),
    /// Symbole `(`
    LParen,
    /// Symbole `)`
    RParen,
    /// Symbole `{`
    LBrace,
    /// Symbole `}`
    RBrace,
    /// Symbole `[`
    LBracket,
    /// Symbole `]`
    RBracket,
    /// `,`
    Comma,
    /// `.`
    Dot,
    /// `;`
    Semi,
    /// `:`
    Colon,
    /// `::`
    PathSep,
    /// `->`
    Arrow,
    /// `=>`
    FatArrow,
    /// `+`
    Plus,
    /// `-`
    Minus,
    /// `*`
    Star,
    /// `/`
    Slash,
    /// `%`
    Percent,
    /// `=`
    Eq,
    /// `==`
    EqEq,
    /// `!=`
    Ne,
    /// `<`
    Lt,
    /// `<=`
    Le,
    /// `>`
    Gt,
    /// `>=`
    Ge,
    /// `&&`
    AndAnd,
    /// `||`
    OrOr,
    /// `!`
    Bang,
}

/// Jeton avec span.
pub type Token<'a> = Spanned<TokenKind<'a>>;

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Erreurs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

/// Genre dâ€™erreur lexicale.
#[derive(Debug, Clone, PartialEq)]
pub enum LexErrorKind {
    /// CaractÃ¨re inattendu.
    UnexpectedChar(char),
    /// Commentaire bloc non terminÃ©.
    UnterminatedBlockComment,
    /// ChaÃ®ne non terminÃ©e.
    UnterminatedString,
    /// Raw string non terminÃ©e (compte de `#` non respectÃ©).
    UnterminatedRawString,
    /// SÃ©quence dâ€™Ã©chappement invalide.
    InvalidEscape,
    /// LittÃ©ral numÃ©rique invalide.
    InvalidNumber,
    /// DÃ©passement entier i64.
    IntOverflow,
    /// LittÃ©ral char invalide.
    InvalidCharLiteral,
    /// Trop de `#` dans un raw string (protÃ¨ge contre abus).
    TooManyRawHashes,
}

/// Erreur lexicale avec localisation.
#[derive(Debug, Clone, PartialEq)]
pub struct LexError {
    /// Localisation.
    pub span: Span,
    /// Genre dâ€™erreur.
    pub kind: LexErrorKind,
}

impl fmt::Display for LexError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        use LexErrorKind::*;
        match &self.kind {
            UnexpectedChar(c) => write!(f, "unexpected character: {c:?}"),
            UnterminatedBlockComment => write!(f, "unterminated block comment"),
            UnterminatedString => write!(f, "unterminated string literal"),
            UnterminatedRawString => write!(f, "unterminated raw string"),
            InvalidEscape => write!(f, "invalid escape sequence"),
            InvalidNumber => write!(f, "invalid number literal"),
            IntOverflow => write!(f, "integer literal overflows i64"),
            InvalidCharLiteral => write!(f, "invalid char literal"),
            TooManyRawHashes => write!(f, "too many raw string hashes"),
        }
    }
}
#[cfg(feature = "std")]
impl std::error::Error for LexError {}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Lexer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

/// Analyseur lexical (itÃ©ratif).
pub struct Lexer<'a> {
    src: &'a str,
    bytes: &'a [u8],
    /// Position courante en bytes.
    off: usize,
    /// Id de la source.
    source: SourceId,
    /// Options.
    opts: LexerOptions,
    /// Table des lignes (exposÃ©e pour diagnostics).
    pub lines: LineMap,
}

impl<'a> Lexer<'a> {
    /// CrÃ©e un lexer avec options par dÃ©faut.
    pub fn new(src: &'a str, source: SourceId) -> Self {
        Self::with_options(src, source, LexerOptions::default())
    }

    /// CrÃ©e un lexer avec `LexerOptions`.
    pub fn with_options(src: &'a str, source: SourceId, opts: LexerOptions) -> Self {
        Self { src, bytes: src.as_bytes(), off: 0, source, opts, lines: LineMap::new(src) }
    }

    /// Prochain jeton (ou `None` si **vraiment** rien â€” ici on Ã©met toujours `Eof`).
    pub fn next(&mut self) -> Result<Option<Token<'a>>, LexError> {
        self.skip_ws_and_comments()?;
        if self.is_eof() {
            let span = self.span_here(0);
            return Ok(Some(Spanned { value: TokenKind::Eof, span }));
        }
        let start = self.off;
        let c = self.bump_char().unwrap(); // safe: non EOF

        let kind = match c {
            ch if is_ident_start(ch) => {
                self.consume_while(|b| is_ident_continue(b as char));
                let s = &self.src[start..self.off];
                match keyword_of(s) {
                    Some(kw) => TokenKind::Kw(kw),
                    None => TokenKind::Ident(s),
                }
            }
            ch if ch.is_ascii_digit() => self.lex_number(start, c)?,
            '"' => TokenKind::Str(self.lex_string(start)?),
            'r' if self.opts.raw_strings && self.peek_char() == Some('"') || self.peek_char() == Some('#') => {
                // 'r' dÃ©jÃ  consommÃ© ; on tente raw string
                self.lex_raw_string(start)?
            }
            '\'' => TokenKind::Char(self.lex_char(start)?),

            ':' => if self.eat(':') { TokenKind::PathSep } else { TokenKind::Colon },
            '-' => if self.eat('>') { TokenKind::Arrow } else { TokenKind::Minus },
            '=' => if self.eat('>') { TokenKind::FatArrow } else if self.eat('=') { TokenKind::EqEq } else { TokenKind::Eq },
            '&' => if self.eat('&') { TokenKind::AndAnd } else { return Err(self.err_here(LexErrorKind::UnexpectedChar('&'))); },
            '|' => if self.eat('|') { TokenKind::OrOr } else { return Err(self.err_here(LexErrorKind::UnexpectedChar('|'))); },
            '!' => if self.eat('=') { TokenKind::Ne } else { TokenKind::Bang },
            '<' => if self.eat('=') { TokenKind::Le } else { TokenKind::Lt },
            '>' => if self.eat('=') { TokenKind::Ge } else { TokenKind::Gt },

            '+' => TokenKind::Plus,
            '*' => TokenKind::Star,
            '/' => TokenKind::Slash,
            '%' => TokenKind::Percent,
            '(' => TokenKind::LParen,
            ')' => TokenKind::RParen,
            '{' => TokenKind::LBrace,
            '}' => TokenKind::RBrace,
            '[' => TokenKind::LBracket,
            ']' => TokenKind::RBracket,
            ',' => TokenKind::Comma,
            ';' => TokenKind::Semi,
            '.' => TokenKind::Dot,

            other => return Err(self.err_spanned(start, LexErrorKind::UnexpectedChar(other))),
        };

        Ok(Some(Spanned { value: kind, span: self.span_from(start) }))
    }

    /// Tokenise toute la source (ajoute `Eof` final).
    pub fn tokenize(mut self) -> Result<Vec<Token<'a>>, LexError> {
        let mut out = Vec::new();
        loop {
            match self.next()? {
                Some(t) => {
                    let is_eof = matches!(t.value, TokenKind::Eof);
                    out.push(t);
                    if is_eof { break; }
                }
                None => break,
            }
        }
        Ok(out)
    }

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Primitives internes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

    #[inline] fn is_eof(&self) -> bool { self.off >= self.bytes.len() }
    #[inline] fn peek(&self) -> Option<u8> { self.bytes.get(self.off).copied() }
    #[inline] fn peek_char(&self) -> Option<char> { self.peek().map(|b| b as char) }
    #[inline] fn peek2(&self) -> Option<u8> { self.bytes.get(self.off + 1).copied() }
    #[inline] fn bump(&mut self) -> Option<u8> { let b = self.peek(); if b.is_some(){ self.off+=1; } b }
    #[inline] fn bump_char(&mut self) -> Option<char> { self.bump().map(|b| b as char) }
    #[inline] fn eat(&mut self, ch: char) -> bool { if self.peek_char()==Some(ch){ self.off+=1; true } else { false } }

    fn consume_while(&mut self, mut p: impl FnMut(u8) -> bool) {
        while let Some(b) = self.peek() {
            if p(b) { self.off += 1; } else { break; }
        }
    }

    fn skip_ws_and_comments(&mut self) -> Result<(), LexError> {
        loop {
            while let Some(c) = self.peek_char() {
                if c.is_whitespace() { self.off += 1; } else { break; }
            }
            if self.peek_char() == Some('/') && self.peek2() == Some(b'/') {
                self.off += 2;
                while let Some(c) = self.peek_char() {
                    self.off += 1;
                    if c == '\n' { break; }
                }
                continue;
            }
            if self.peek_char() == Some('/') && self.peek2() == Some(b'*') {
                self.off += 2;
                let start = self.off.saturating_sub(2);
                let mut depth = 1u32;
                loop {
                    if self.is_eof() { return Err(self.err_from(start, LexErrorKind::UnterminatedBlockComment)); }
                    if self.opts.nested_block_comments && self.peek_char() == Some('/') && self.peek2() == Some(b'*') {
                        self.off += 2; depth += 1; continue;
                    }
                    if self.peek_char() == Some('*') && self.peek2() == Some(b'/') {
                        self.off += 2; depth -= 1;
                        if depth == 0 { break; }
                        continue;
                    }
                    self.off += 1;
                }
                continue;
            }
            break;
        }
        Ok(())
    }

    fn lex_string(&mut self, start_quote: usize) -> Result<String, LexError> {
        let mut out = String::new();
        loop {
            let c = self.bump_char().ok_or_else(|| self.err_from(start_quote, LexErrorKind::UnterminatedString))?;
            match c {
                '"' => break,
                '\\' => {
                    let esc = self.bump_char().ok_or_else(|| self.err_here(LexErrorKind::UnterminatedString))?;
                    match esc {
                        '"' => out.push('"'),
                        '\\' => out.push('\\'),
                        'n' => out.push('\n'),
                        'r' => out.push('\r'),
                        't' => out.push('\t'),
                        '0' => out.push('\0'),
                        'x' => {
                            let h1 = self.bump_char().ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))?;
                            let h2 = self.bump_char().ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))?;
                            let v = (hex_val(h1).ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))? << 4)
                                | hex_val(h2).ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))?;
                            out.push(v as char);
                        }
                        'u' => out.push(self.read_unicode_escape()?),
                        _ => return Err(self.err_here(LexErrorKind::InvalidEscape)),
                    }
                }
                other => out.push(other),
            }
        }
        Ok(out)
    }

    fn lex_raw_string(&mut self, start_r: usize) -> Result<TokenKind<'a>, LexError> {
        // On a dÃ©jÃ  lu 'r'. Lit 0..=N '#' puis un '"', jusquâ€™au mÃªme nombre de '#' et un '"'.
        if !self.opts.raw_strings {
            return Err(self.err_from(start_r, LexErrorKind::UnexpectedChar('r')));
        }
        // Compter les '#'
        let mut hashes: u8 = 0;
        while self.peek_char() == Some('#') {
            hashes = hashes.saturating_add(1);
            if hashes > self.opts.max_raw_hashes { return Err(self.err_from(start_r, LexErrorKind::TooManyRawHashes)); }
            self.off += 1;
        }
        if !self.eat('"') {
            // ce nâ€™Ã©tait pas un raw string, câ€™Ã©tait juste un ident "r..."
            // on recule ? trop tard. On choisit lâ€™erreur claire :
            return Err(self.err_from(start_r, LexErrorKind::InvalidNumber)); // faute bÃ©nigne : â€œrXâ€ inattendu
        }
        let content_start = self.off;
        // Chercher la fin : un `"` suivi de `hashes` fois '#'
        loop {
            if self.is_eof() { return Err(self.err_from(start_r, LexErrorKind::UnterminatedRawString)); }
            if self.peek_char() == Some('"') {
                // check hashes
                let mut ok = true;
                let mut i = 0;
                while i < hashes {
                    if self.bytes.get(self.off + 1 + (i as usize)) != Some(&b'#') { ok = false; break; }
                    i += 1;
                }
                if ok {
                    // consume closing '"' and hashes
                    self.off += 1 + (hashes as usize);
                    break;
                }
            }
            self.off += 1;
        }
        let s = &self.src[content_start..self.off - (hashes as usize) - 1];
        Ok(TokenKind::Str(s.to_string()))
    }

    fn lex_char(&mut self, start_quote: usize) -> Result<char, LexError> {
        // Lit un littÃ©ral char : `'a'`, `'\n'`, `'\x41'`, `'\u{1F600}'`
        let ch = match self.bump_char().ok_or_else(|| self.err_from(start_quote, LexErrorKind::InvalidCharLiteral))? {
            '\\' => {
                let e = self.bump_char().ok_or_else(|| self.err_here(LexErrorKind::InvalidCharLiteral))?;
                match e {
                    '\'' => '\'',
                    '"'  => '"',
                    '\\' => '\\',
                    'n'  => '\n',
                    'r'  => '\r',
                    't'  => '\t',
                    '0'  => '\0',
                    'x'  => {
                        let h1 = self.bump_char().ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))?;
                        let h2 = self.bump_char().ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))?;
                        let v = (hex_val(h1).ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))? << 4)
                            | hex_val(h2).ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))?;
                        v as char
                    }
                    'u'  => self.read_unicode_escape()?,
                    _    => return Err(self.err_here(LexErrorKind::InvalidCharLiteral)),
                }
            }
            c => c,
        };
        if !self.eat('\'') { return Err(self.err_here(LexErrorKind::InvalidCharLiteral)); }
        Ok(ch)
    }

    fn read_unicode_escape(&mut self) -> Result<char, LexError> {
        if !self.eat('{') { return Err(self.err_here(LexErrorKind::InvalidEscape)); }
        let start = self.off;
        while let Some(c) = self.peek_char() {
            if c == '}' { break; }
            if !(c.is_ascii_hexdigit() || c == '_') { return Err(self.err_here(LexErrorKind::InvalidEscape)); }
            self.off += 1;
        }
        if !self.eat('}') { return Err(self.err_here(LexErrorKind::InvalidEscape)); }
        let raw = &self.src[start..self.off].replace('_', "");
        let v = u32::from_str_radix(raw, 16).map_err(|_| self.err_here(LexErrorKind::InvalidEscape))?;
        core::char::from_u32(v).ok_or_else(|| self.err_here(LexErrorKind::InvalidEscape))
    }

    fn lex_number(&mut self, start: usize, first: char) -> Result<TokenKind<'a>, LexError> {
        if first == '0' {
            if self.peek_char().map(|c| c == 'x' || c == 'X').unwrap_or(false) {
                self.off += 1;
                self.consume_while(|b| is_digit_base(b as char, 16) || b == b'_');
                let raw = self.src[start + 2..self.off].replace('_', "");
                let v = i64::from_str_radix(&raw, 16).map_err(|_| self.err_from(start, LexErrorKind::IntOverflow))?;
                return Ok(TokenKind::Int(v));
            } else if self.peek_char().map(|c| c == 'b' || c == 'B').unwrap_or(false) {
                self.off += 1;
                self.consume_while(|b| is_digit_base(b as char, 2) || b == b'_');
                let raw = self.src[start + 2..self.off].replace('_', "");
                let v = i64::from_str_radix(&raw, 2).map_err(|_| self.err_from(start, LexErrorKind::IntOverflow))?;
                return Ok(TokenKind::Int(v));
            } else if self.peek_char().map(|c| c == 'o' || c == 'O').unwrap_or(false) {
                self.off += 1;
                self.consume_while(|b| is_digit_base(b as char, 8) || b == b'_');
                let raw = self.src[start + 2..self.off].replace('_', "");
                let v = i64::from_str_radix(&raw, 8).map_err(|_| self.err_from(start, LexErrorKind::IntOverflow))?;
                return Ok(TokenKind::Int(v));
            }
        }

        // DÃ©cimal / flottant
        self.consume_while(|b| (b as char).is_ascii_digit() || b == b'_');
        let mut saw_dot = false;
        let mut saw_exp = false;
        if self.peek_char() == Some('.') && self.peek2().map(|d| (d as char).is_ascii_digit()).unwrap_or(false) {
            saw_dot = true;
            self.off += 1;
            self.consume_while(|b| (b as char).is_ascii_digit() || b == b'_');
        }
        if matches!(self.peek_char(), Some('e' | 'E')) {
            saw_exp = true;
            self.off += 1;
            if matches!(self.peek_char(), Some('+' | '-')) { self.off += 1; }
            self.consume_while(|b| (b as char).is_ascii_digit() || b == b'_');
        }

        let raw = self.src[start..self.off].replace('_', "");
        if saw_dot || saw_exp {
            let v = raw.parse::<f64>().map_err(|_| self.err_from(start, LexErrorKind::InvalidNumber))?;
            Ok(TokenKind::Float(v))
        } else {
            raw.parse::<i64>()
               .map(TokenKind::Int)
               .map_err(|_| self.err_from(start, LexErrorKind::IntOverflow))
        }
    }

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Spans / erreurs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

    #[inline] fn span_here(&self, width: usize) -> Span {
        Span { source: self.source, start: Pos(self.off as u32), end: Pos((self.off + width) as u32) }
    }
    #[inline] fn span_from(&self, start: usize) -> Span {
        Span { source: self.source, start: Pos(start as u32), end: Pos(self.off as u32) }
    }
    #[inline] fn err_here(&self, kind: LexErrorKind) -> LexError { LexError { span: self.span_here(1), kind } }
    #[inline] fn err_from(&self, start: usize, kind: LexErrorKind) -> LexError { LexError { span: self.span_from(start), kind } }
    #[inline] fn err_spanned(&self, start: usize, kind: LexErrorKind) -> LexError { LexError { span: self.span_from(start), kind } }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

#[inline]
fn is_ident_start(c: char) -> bool { c == '_' || c.is_ascii_alphabetic() }

#[inline]
fn is_ident_continue(c: char) -> bool { c == '_' || c.is_ascii_alphanumeric() }

#[inline]
fn is_digit_base(c: char, base: u32) -> bool {
    match base {
        2 => matches!(c, '0' | '1'),
        8 => c.is_ascii_digit() && c < '8',
        10 => c.is_ascii_digit(),
        16 => c.is_ascii_hexdigit(),
        _ => false,
    }
}

#[inline]
fn keyword_of(s: &str) -> Option<Keyword> {
    use Keyword::*;
    Some(match s {
        "fn" => Fn,
        "let" => Let,
        "const" => Const,
        "if" => If,
        "else" => Else,
        "while" => While,
        "for" => For,
        "return" => Return,
        "struct" => Struct,
        "enum" => Enum,
        "true" => True,
        "false" => False,
        "null" => Null,
        _ => return None,
    })
}

#[inline]
fn hex_val(c: char) -> Option<u8> {
    match c {
        '0'..='9' => Some((c as u8) - b'0'),
        'a'..='f' => Some((c as u8) - b'a' + 10),
        'A'..='F' => Some((c as u8) - b'A' + 10),
        _ => None,
    }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tests â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

#[cfg(test)]
mod tests {
    use super::*;

    fn toks(src: &str) -> Vec<TokenKind<'_>> {
        let mut lx = Lexer::new(src, SourceId(0));
        let mut out = Vec::new();
        loop {
            let t = lx.next().unwrap().unwrap();
            let end = matches!(t.value, TokenKind::Eof);
            out.push(t.value);
            if end { break; }
        }
        out
    }

    #[test]
    fn idents_keywords() {
        use Keyword::*;
        use TokenKind::*;
        let v = toks("fn let const if else while for return struct enum true false null ident _x x1");
        assert!(matches!(v[0], Kw(Fn)));
        assert!(matches!(v[1], Kw(Let)));
        assert!(matches!(v[2], Kw(Const)));
        assert!(matches!(v[3], Kw(If)));
        assert!(matches!(v[4], Kw(Else)));
        assert!(matches!(v[5], Kw(While)));
        assert!(matches!(v[6], Kw(For)));
        assert!(matches!(v[7], Kw(Return)));
        assert!(matches!(v[8], Kw(Struct)));
        assert!(matches!(v[9], Kw(Enum)));
        assert!(matches!(v[10], Kw(True)));
        assert!(matches!(v[11], Kw(False)));
        assert!(matches!(v[12], Kw(Null)));
        assert!(matches!(v[13], Ident("ident")));
        assert!(matches!(v[14], Ident("_x")));
        assert!(matches!(v[15], Ident("x1")));
    }

    #[test]
    fn numbers_and_floats() {
        use TokenKind::*;
        let v = toks("0xFF 0o77 0b1010 123 1_234 12.34 1e3 2.5e-2");
        assert_eq!(v[0], Int(255));
        assert_eq!(v[1], Int(63));
        assert_eq!(v[2], Int(10));
        assert_eq!(v[3], Int(123));
        assert_eq!(v[4], Int(1234));
        if let Float(f) = v[5] { assert!((f - 12.34).abs() < 1e-9) } else { panic!() }
        if let Float(f) = v[6] { assert!((f - 1000.0).abs() < 1e-9) } else { panic!() }
        if let Float(f) = v[7] { assert!((f - 0.025).abs() < 1e-9) } else { panic!() }
    }

    #[test]
    fn strings_escapes_chars() {
        use TokenKind::*;
        let v = toks(r#""hi" "\n" "\x41" "\u{1F600}" 'a' '\n' '\x41' '\u{61}'"#);
        assert_eq!(v[0], Str("hi".into()));
        assert_eq!(v[1], Str("\n".into()));
        assert_eq!(v[2], Str("A".into()));
        assert_eq!(v[3], Str("ğŸ˜€".into()));
        assert_eq!(v[4], Char('a'));
        assert_eq!(v[5], Char('\n'));
        assert_eq!(v[6], Char('A'));
        assert_eq!(v[7], Char('a'));
    }

    #[test]
    fn raw_strings() {
        use TokenKind::*;
        let v = toks(r###"r"ok" r#"multi " hash"# r##"## inside "##"##"###);
        assert_eq!(v[0], Str("ok".into()));
        assert_eq!(v[1], Str("multi \" hash".into()));
        assert_eq!(v[2], Str("## inside \"##".into()));
    }

    #[test]
    fn comments_ws() {
        use TokenKind::*;
        let v = toks("/* a /* nested */ still */ + // line\n 1");
        assert!(matches!(v[0], Plus));
        assert_eq!(v[1], Int(1));
    }

    #[test]
    fn ops_punct() {
        use TokenKind::*;
        let v = toks(":: -> => == != <= >= && || ! + - * / % ( ) { } [ ] , . ; : < > =");
        assert!(matches!(v[0], PathSep));
        assert!(matches!(v[1], Arrow));
        assert!(matches!(v[2], FatArrow));
        assert!(matches!(v[3], EqEq));
        assert!(matches!(v[4], Ne));
        assert!(matches!(v[5], Le));
        assert!(matches!(v[6], Ge));
        assert!(matches!(v[7], AndAnd));
        assert!(matches!(v[8], OrOr));
        assert!(matches!(v[9], Bang));
        assert!(matches!(v[10], Plus));
        assert!(matches!(v[11], Minus));
        assert!(matches!(v[12], Star));
        assert!(matches!(v[13], Slash));
        assert!(matches!(v[14], Percent));
        assert!(matches!(v[15], LParen));
        assert!(matches!(v[16], RParen));
        assert!(matches!(v[17], LBrace));
        assert!(matches!(v[18], RBrace));
        assert!(matches!(v[19], LBracket));
        assert!(matches!(v[20], RBracket));
        assert!(matches!(v[21], Comma));
        assert!(matches!(v[22], Dot));
        assert!(matches!(v[23], Semi));
        assert!(matches!(v[24], Colon));
        assert!(matches!(v[25], Lt));
        assert!(matches!(v[26], Gt));
        assert!(matches!(v[27], Eq));
    }

    #[test]
    fn linemap_basic() {
        let src = "a\nbb\nccc";
        let lm = LineMap::new(src);
        assert_eq!(lm.line_col(Pos(0)), (1,1));
        assert_eq!(lm.line_col(Pos(2)), (2,1));
        assert_eq!(lm.line_col(Pos(4)), (3,1));
        assert_eq!(lm.line_col(Pos(6)), (3,3));
    }
}
